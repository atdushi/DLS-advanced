{"cells":[{"cell_type":"markdown","metadata":{"id":"pgFYFftQKxY5"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","<h3 style=\"text-align: center;\"><b>Базовый и продвинутый потоки. Осень 2021</b></h3>\n","\n","<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"]},{"cell_type":"markdown","metadata":{"id":"v4RCHGZULaWz"},"source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."]},{"cell_type":"markdown","metadata":{"id":"F2acNQu1L94J"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Twe_cnn5KxY6"},"source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"YD0NXyUYKxY7"},"source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "]},{"cell_type":"markdown","metadata":{"id":"CTa2jNZkKxY8"},"source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"]},{"cell_type":"markdown","metadata":{"id":"5H7wPU0IKxY-"},"source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"]},{"cell_type":"markdown","metadata":{"id":"T2docs4225pb"},"source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."]},{"cell_type":"markdown","metadata":{"id":"AcjJQX3wKxZA"},"source":["### Обработка данных"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"Ozcx5mVOKxZB"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Ry4bMKaUjHJj"},"source":["Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"rvPrVRvK25pc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 55 columns</p>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7    8     9  ...  45  46  47  48  49  \\\n","0  2683  333  35   30  26  2743  121  173  179  6572  ...   0   0   0   0   0   \n","1  2915   90   8  216  11  4433  232  228  129  4019  ...   0   0   0   0   0   \n","2  2941  162   7  698  76  2783  227  242  148  1784  ...   0   0   0   0   0   \n","3  3096   60  17  170   3  3303  231  202   99  5370  ...   0   0   0   0   0   \n","4  2999   66   8  488  37  1532  228  225  131  2290  ...   0   0   0   0   0   \n","\n","   50  51  52  53  54  \n","0   0   0   0   0   2  \n","1   0   0   0   0   1  \n","2   0   0   0   0   2  \n","3   0   0   0   0   1  \n","4   0   0   0   0   2  \n","\n","[5 rows x 55 columns]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["all_data = pd.read_csv('forest_dataset.csv')\n","all_data.head()"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"_o8yXBPSKxZI"},"outputs":[{"data":{"text/plain":["(10000, 55)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["all_data.shape"]},{"cell_type":"markdown","metadata":{"id":"itCWxHEY25pg"},"source":["Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"f_YIUOuV25ph"},"outputs":[],"source":["labels = all_data[all_data.columns[-1]].values\n","feature_matrix = all_data[all_data.columns[:-1]].values"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 2, 3, 4, 5, 6, 7])"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(labels)\n"]},{"cell_type":"markdown","metadata":{"id":"FukXaH_r8PMQ"},"source":["### Пара слов о sklearn"]},{"cell_type":"markdown","metadata":{"id":"k5S_0Lfc8PMR"},"source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."]},{"cell_type":"markdown","metadata":{"id":"VhVDEG538PMS"},"source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."]},{"cell_type":"markdown","metadata":{"id":"QJZQulsp8PMT"},"source":["Познакомимся со вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на обучающую и тестовую части."]},{"cell_type":"code","execution_count":60,"metadata":{"id":"Q030jzyY25pl"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"UkeB47mX8PMY"},"source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"YJN0jFARKxZX"},"outputs":[],"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n","    feature_matrix, labels, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"odC1c7X48PMb"},"source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"markdown","metadata":{"id":"z3fGvPqG8PMc"},"source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."]},{"cell_type":"markdown","metadata":{"id":"IuX8Rc7c8PMd"},"source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."]},{"cell_type":"markdown","metadata":{"id":"ZYokUkxO8PMe"},"source":["Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"ew0Ji_2D8PMe"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"c9KcMHXr8PMh"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["# создание модели с указанием гиперпараметра C\n","clf = LogisticRegression(C=1)\n","# обучение модели\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)\n","\n","None"]},{"cell_type":"markdown","metadata":{"id":"h3gjg3pm8PMm"},"source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"J2Ej1Lni8PMn"},"outputs":[{"data":{"text/plain":["0.6075"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"malIDW_P8PMp"},"source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"vq687Aoc8PMq"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"OVnqHBvK8PMs"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["{'C': 1, 'penalty': 'l1'}\n"]},{"name":"stderr","output_type":"stream","text":["/home/maxim/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["# заново создадим модель, указав солвер\n","clf = LogisticRegression(solver='saga')\n","\n","# опишем сетку, по которой будем искать\n","param_grid = {\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'penalty': ['l1', 'l2'],\n","}\n","\n","# создадим объект GridSearchCV\n","search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n","\n","# запустим поиск\n","search.fit(feature_matrix, labels)\n","\n","# выведем наилучшие параметры\n","print(search.best_params_)\n","\n","None"]},{"cell_type":"markdown","metadata":{"id":"DnVTFcvZ8PMv"},"source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ArKINrE_8PMw"},"outputs":[{"data":{"text/plain":["0.6419"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"]},{"cell_type":"markdown","metadata":{"id":"okzpKY_I8PMz"},"source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."]},{"cell_type":"markdown","metadata":{"id":"_mdJyxdo8PM1"},"source":["В заданиях вам предстоит повторить это для метода ближайших соседей."]},{"cell_type":"markdown","metadata":{"id":"z8W__017KxZc"},"source":["### Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"02uT6CPYKxZe"},"source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"]},{"cell_type":"markdown","metadata":{"id":"BHVNCaJ325qD"},"source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"o4CMnnOY25qD"},"outputs":[{"data":{"text/plain":["0.7365"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","clf = KNeighborsClassifier()\n","clf.fit(train_feature_matrix, train_labels)\n","y_pred = clf.predict(test_feature_matrix)\n","\n","accuracy_score(test_labels, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"r_2Mf8BiKxZk"},"source":["### Вопрос 1:\n","* Какое качество у вас получилось?"]},{"cell_type":"markdown","metadata":{"id":"uFTIaPdrKxZl"},"source":["Подберём параметры нашей модели"]},{"cell_type":"markdown","metadata":{"id":"8WzoRJZd25qF"},"source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4lMSy-6f25qG","scrolled":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","# опишем сетку, по которой будем искать\n","params = {\n","    'n_neighbors': np.arange(1, 11), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'metric': ['manhattan', 'euclidean'],\n","    'weights': ['uniform', 'distance']\n","}\n","\n","clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n","# Теперь обучение. Ваш код здесь\n","\n","# запустим поиск\n","clf_grid.fit(feature_matrix, labels)\n","\n","None"]},{"cell_type":"markdown","metadata":{"id":"SO7E6G8jKxZp"},"source":["Выведем лучшие параметры"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"md48pHrMKxZq"},"outputs":[{"data":{"text/plain":["({'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'},\n"," KNeighborsClassifier(metric='manhattan', n_neighbors=4, weights='distance'))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["clf_grid.best_params_, clf_grid.best_estimator_"]},{"cell_type":"markdown","metadata":{"id":"M05n9l8pKxZt"},"source":["### Вопрос 2:\n","* Какую metric следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"Pmjx38OoKxZt"},"source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"eqLeJUP8KxZu"},"source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"aBmiDbvV25qI"},"source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ig_vS8O925qI"},"outputs":[],"source":["optimal_clf = clf.set_params(**clf_grid.best_params_)\n","\n","# Обучение.\n","optimal_clf.fit(feature_matrix, labels)\n","\n","pred_prob = clf.predict_proba(test_feature_matrix)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"2kkapT38KxZz"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","\n","unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","\n","pred_freq = pred_prob.mean(axis=0)\n","plt.figure(figsize=(10, 8))\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n","plt.ylim(0, 0.54)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gp4uDyLmKxZ3"},"source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(2000, 7) 0.14285714285714285 (7,) (2000,)\n"]},{"data":{"text/plain":["(array([[0., 1., 0., ..., 0., 0., 0.],\n","        [1., 0., 0., ..., 0., 0., 0.],\n","        [0., 1., 0., ..., 0., 0., 0.],\n","        ...,\n","        [1., 0., 0., ..., 0., 0., 0.],\n","        [0., 1., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 1.]]),\n"," 0.14285714285714285,\n"," array([0.368 , 0.4865, 0.0555, 0.0055, 0.0165, 0.028 , 0.04  ]))"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["np.round(pred_prob.mean(axis=0), 2)\n","\n","print(pred_prob.shape, pred_prob.mean(), pred_prob.mean(axis=0).shape, pred_prob.mean(axis=1).shape)\n","\n","pred_prob, pred_prob.mean(), pred_prob.mean(axis=0)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"[homework,adv]knn.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
